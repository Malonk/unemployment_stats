{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert files\n",
    "We have a bunch of tsv files that need initial cleaning. At the end we save it as a pickle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE = os.path.join(os.pardir, \"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def list_tsv():\n",
    "    \"\"\"Return list of tsv files\"\"\"\n",
    "      \n",
    "    return [x for x in os.listdir(os.path.join(BASE, \"tsv\"))]\n",
    "\n",
    "def simplify_col(col):\n",
    "    \"\"\"Return column as series with dtype float.\"\"\"\n",
    "    \n",
    "    # Skip if already numeric\n",
    "    if col.dtype in [\"float64\", \"int64\"]:\n",
    "        return col\n",
    "    \n",
    "    def _split_str(x):\n",
    "        \"\"\"Split string on space and return numbers.\"\"\"\n",
    "        \n",
    "        x = x.split()\n",
    "        return x[0] if isinstance(x, list) else x\n",
    "    \n",
    "    # If value is ':' > set as NaN, otherwise apply func above\n",
    "    col = (np.where(col.str.contains(\":\"), \n",
    "                        pd.NA, \n",
    "                        col.apply(_split_str)))    \n",
    "    \n",
    "    # Return as numeric column\n",
    "    return pd.to_numeric(col, errors=\"coerce\")\n",
    "\n",
    "def split_first_col(df):\n",
    "    \"\"\"Split first column and return as df.\"\"\"\n",
    "    \n",
    "    # First save a list of other column names\n",
    "    other_cols = list(df.columns[1:])\n",
    "    \n",
    "    # Split the first column in diff variables\n",
    "    new_names = df.columns[0].split(\",\")\n",
    "    new_names[-1] = new_names[-1].split(\"\\\\\")[0]\n",
    "    \n",
    "    # Save the variables as new columns\n",
    "    df[new_names] = df.iloc[:,0].str.split(\",\", expand=True) \n",
    "    df = df[new_names + other_cols]\n",
    "    \n",
    "    # Clean the column names\n",
    "    df.columns = [col.lower().strip() for col in df.columns]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "\n",
    "def clean_df(filename, replace=True):\n",
    "    \"\"\"Take filename, create & clean df and save as pickel.\"\"\"\n",
    "    \n",
    "    # Skip file it exists and if flag set to false\n",
    "    newname = filename.split(\".\")[0]\n",
    "    if (not replace \n",
    "        and os.path.exists(os.path.join(BASE, \"pickles\", f\"{newname}.pkl\"))):\n",
    "        return f\"{filename} skipped\"\n",
    "    \n",
    "    # Open file\n",
    "    df = pd.read_csv(os.path.join(BASE, \"tsv\", filename), sep=\"\\t\")\n",
    "    \n",
    "    # Set ':' values to pd.NA and rest to numeric\n",
    "    for col in df.columns[1:]:\n",
    "        df[col] = simplify_col(df[col])\n",
    "    \n",
    "    # Convert variables in first column to seperate columns\n",
    "    df = split_first_col(df) \n",
    "    \n",
    "    # Save files\n",
    "    df.to_pickle(os.path.join(BASE, \"pickles\", f\"{newname}.pkl\"))\n",
    "    df.to_csv(os.path.join(BASE, \"pickles\", f\"{newname}.csv\"))\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilc_di12.tsv\n",
      "lfsq_egan.tsv skipped\n",
      "sdg_08_40.tsv skipped\n",
      "t2020_10.tsv skipped\n",
      "tec00114.tsv skipped\n",
      "teilm010.tsv skipped\n",
      "teilm011.tsv skipped\n",
      "teilm012.tsv skipped\n",
      "teilm020.tsv skipped\n",
      "teilm021.tsv skipped\n",
      "teilm022.tsv skipped\n",
      "tepsr_wc120.tsv skipped\n",
      "tgs00007.tsv skipped\n",
      "tgs00010.tsv skipped\n",
      "tgs00053.tsv skipped\n",
      "tgs00102.tsv skipped\n",
      "tps00066.tsv skipped\n",
      "tps00070.tsv skipped\n",
      "tps00071.tsv skipped\n",
      "tps00073.tsv skipped\n",
      "tps00074.tsv skipped\n",
      "tps00159.tsv skipped\n",
      "tps00181.tsv skipped\n",
      "tps00182.tsv skipped\n",
      "tps00203.tsv skipped\n"
     ]
    }
   ],
   "source": [
    "# Execute the code and print results\n",
    "\n",
    "files = list_tsv()\n",
    "\n",
    "for filename in files:\n",
    "    print(clean_df(filename, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
